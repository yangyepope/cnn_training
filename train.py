"""
è®­ç»ƒè„šæœ¬
========
ç”¨äºè®­ç»ƒé¢œå€¼é¢„æµ‹CNNæ¨¡å‹çš„ä¸»è„šæœ¬

ä½¿ç”¨æ–¹æ³•ï¼š
---------
# ä½¿ç”¨é»˜è®¤å‚æ•°è®­ç»ƒ
python train.py

# è‡ªå®šä¹‰å‚æ•°
python train.py --epochs 30 --batch_size 8 --model resnet18

è®­ç»ƒæµç¨‹ï¼š
---------
1. è§£æå‘½ä»¤è¡Œå‚æ•°
2. åŠ è½½æ•°æ®é›†ï¼Œåˆ’åˆ†è®­ç»ƒé›†/éªŒè¯é›†
3. åˆ›å»ºæ¨¡å‹
4. è®­ç»ƒå¾ªç¯ï¼š
   - éå†è®­ç»ƒé›†ï¼Œæ›´æ–°æ¨¡å‹å‚æ•°
   - åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹
   - ä¿å­˜æœ€ä½³æ¨¡å‹
5. è¾“å‡ºæœ€ç»ˆç»“æœ
"""

# ==============================================================================
# å¯¼å…¥å¿…è¦çš„åº“
# ==============================================================================

import os
import argparse
import time
import numpy as np
import math

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader

from config import (
    IMAGES_DIR, RATINGS_FILE, MODEL_SAVE_PATH,
    DEFAULT_EPOCHS, DEFAULT_BATCH_SIZE, DEFAULT_LR,
    TRAIN_RATIO, RANDOM_SEED, DEFAULT_MODEL
)
from dataset import BeautyDataset, get_train_transform, get_val_transform
from model import BeautyModel


# ==============================================================================
# è®­ç»ƒä¸€ä¸ªEpochçš„å‡½æ•°
# ==============================================================================

def train_one_epoch(model, dataloader, criterion, optimizer, device, epoch, total_epochs):
    """
    è®­ç»ƒä¸€ä¸ªepoch
    """
    model.train()
    total_loss = 0
    valid_batches = 0  # æœ‰æ•ˆbatchè®¡æ•°
    batch_count = len(dataloader)
    
    start_time = time.time()
    
    for batch_idx, (images, ratings) in enumerate(dataloader):
        images = images.to(device)
        ratings = ratings.to(device)
        
        # å‰å‘ä¼ æ’­
        outputs = model(images)
        
        # è®¡ç®—æŸå¤±
        loss = criterion(outputs, ratings)
        
        # æ£€æŸ¥lossæ˜¯å¦ä¸ºnanæˆ–infï¼Œå¦‚æœæ˜¯åˆ™è·³è¿‡è¿™ä¸ªbatch
        if math.isnan(loss.item()) or math.isinf(loss.item()):
            print(f"  âš ï¸ Batch {batch_idx}: Loss is nan/inf, skipping...")
            continue
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        
        # æ¢¯åº¦è£å‰ªï¼šé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸å¯¼è‡´nan
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        
        optimizer.step()
        
        total_loss += loss.item()
        valid_batches += 1
        
        # æ‰“å°è¿›åº¦
        if (batch_idx + 1) % 50 == 0 or (batch_idx + 1) == batch_count:
            elapsed = time.time() - start_time
            eta = elapsed / (batch_idx + 1) * (batch_count - batch_idx - 1)
            current_avg_loss = total_loss / valid_batches if valid_batches > 0 else 0
            print(f"  Epoch [{epoch}/{total_epochs}] "
                  f"Batch [{batch_idx + 1}/{batch_count}] "
                  f"Loss: {loss.item():.4f} "
                  f"Avg: {current_avg_loss:.4f} "
                  f"ETA: {eta/60:.1f}min")
    
    return total_loss / valid_batches if valid_batches > 0 else float('inf')


# ==============================================================================
# è¯„ä¼°å‡½æ•°
# ==============================================================================

def evaluate(model, dataloader, criterion, device):
    """
    åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½
    """
    model.eval()
    total_loss = 0
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for images, ratings in dataloader:
            images = images.to(device)
            ratings = ratings.to(device)
            
            outputs = model(images)
            loss = criterion(outputs, ratings)
            
            # è·³è¿‡æ— æ•ˆçš„loss
            if not (math.isnan(loss.item()) or math.isinf(loss.item())):
                total_loss += loss.item()
            
            all_preds.extend(outputs.cpu().numpy())
            all_labels.extend(ratings.cpu().numpy())
    
    all_preds = np.array(all_preds)
    all_labels = np.array(all_labels)
    
    # è¿‡æ»¤æ‰nanå€¼
    valid_mask = ~(np.isnan(all_preds) | np.isnan(all_labels))
    all_preds = all_preds[valid_mask]
    all_labels = all_labels[valid_mask]
    
    if len(all_preds) == 0:
        return float('inf'), float('inf'), float('inf'), 0
    
    # è½¬å›1-5åˆ†
    preds_original = all_preds * 4.0 + 1.0
    labels_original = all_labels * 4.0 + 1.0
    
    mae = np.mean(np.abs(preds_original - labels_original))
    mse = np.mean((preds_original - labels_original) ** 2)
    rmse = np.sqrt(mse)
    
    if len(preds_original) > 1:
        correlation = np.corrcoef(preds_original, labels_original)[0, 1]
    else:
        correlation = 0
    
    return total_loss / len(dataloader), mae, rmse, correlation


# ==============================================================================
# ä¸»å‡½æ•°
# ==============================================================================

def main():
    """
    ä¸»å‡½æ•°ï¼šç¨‹åºçš„å…¥å£ç‚¹
    """
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="CNNé¢œå€¼é¢„æµ‹æ¨¡å‹è®­ç»ƒ")
    parser.add_argument("--epochs", type=int, default=DEFAULT_EPOCHS, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--batch_size", type=int, default=DEFAULT_BATCH_SIZE, help="æ‰¹å¤§å°")
    parser.add_argument("--lr", type=float, default=DEFAULT_LR, help="å­¦ä¹ ç‡")
    parser.add_argument("--model", type=str, default=DEFAULT_MODEL,
                       choices=["mobilenet", "resnet18", "resnet34"], help="æ¨¡å‹é€‰æ‹©")
    parser.add_argument("--images_dir", type=str, default=IMAGES_DIR, help="å›¾ç‰‡ç›®å½•")
    parser.add_argument("--ratings_file", type=str, default=RATINGS_FILE, help="è¯„åˆ†æ–‡ä»¶")
    parser.add_argument("--save_path", type=str, default=MODEL_SAVE_PATH, help="æ¨¡å‹ä¿å­˜è·¯å¾„")
    args = parser.parse_args()
    
    print("=" * 60)
    print("CNN é¢œå€¼é¢„æµ‹æ¨¡å‹è®­ç»ƒ")
    print("=" * 60)
    
    # é€‰æ‹©è®¡ç®—è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"\nğŸ“± è®¡ç®—è®¾å¤‡: {device}")
    
    if device.type == 'cpu':
        print("âš ï¸  ä½¿ç”¨CPUè®­ç»ƒï¼Œé€Ÿåº¦è¾ƒæ…¢ï¼Œè¯·è€å¿ƒç­‰å¾…...")
    
    # åŠ è½½æ•°æ®é›†
    print("\nğŸ“‚ åŠ è½½æ•°æ®é›†...")
    train_transform = get_train_transform()
    val_transform = get_val_transform()
    
    full_dataset = BeautyDataset(args.images_dir, args.ratings_file, transform=train_transform)
    
    if len(full_dataset) == 0:
        print("âŒ æ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥è·¯å¾„é…ç½®ï¼")
        return
    
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    train_size = int(TRAIN_RATIO * len(full_dataset))
    val_size = len(full_dataset) - train_size
    
    train_dataset, val_dataset = torch.utils.data.random_split(
        full_dataset, [train_size, val_size],
        generator=torch.Generator().manual_seed(RANDOM_SEED)
    )
    
    print(f"   è®­ç»ƒé›†: {train_size} å¼ å›¾ç‰‡")
    print(f"   éªŒè¯é›†: {val_size} å¼ å›¾ç‰‡")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=0,
        pin_memory=False
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=0,
        pin_memory=False
    )
    
    # åˆ›å»ºæ¨¡å‹
    print(f"\nğŸ”§ åˆ›å»ºæ¨¡å‹: {args.model}")
    model = BeautyModel(model_name=args.model)
    model = model.to(device)
    
    total_params, trainable_params = model.count_parameters()
    print(f"   æ€»å‚æ•°é‡: {total_params:,}")
    print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    
    # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.MSELoss()
    
    # ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡ï¼Œå¹¶ä¸”ä½¿ç”¨æƒé‡è¡°å‡é˜²æ­¢è¿‡æ‹Ÿåˆ
    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-5)
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=3, verbose=True
    )
    
    # æ‰“å°è®­ç»ƒé…ç½®
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    print(f"   è®­ç»ƒè½®æ•°: {args.epochs}")
    print(f"   æ‰¹å¤§å°: {args.batch_size}")
    print(f"   å­¦ä¹ ç‡: {args.lr}")
    print()
    
    # è®­ç»ƒå¾ªç¯
    best_mae = float('inf')
    best_correlation = 0
    train_start = time.time()
    
    for epoch in range(1, args.epochs + 1):
        epoch_start = time.time()
        
        # è®­ç»ƒ
        train_loss = train_one_epoch(
            model, train_loader, criterion, optimizer, device, epoch, args.epochs
        )
        
        # éªŒè¯
        val_loss, mae, rmse, correlation = evaluate(model, val_loader, criterion, device)
        
        epoch_time = time.time() - epoch_start
        
        # æ›´æ–°å­¦ä¹ ç‡ï¼ˆæ ¹æ®éªŒè¯æŸå¤±ï¼‰
        scheduler.step(val_loss)
        
        # æ‰“å°ç»“æœ
        print(f"\nğŸ“Š Epoch {epoch}/{args.epochs} å®Œæˆ (è€—æ—¶: {epoch_time/60:.1f}åˆ†é’Ÿ)")
        print(f"   è®­ç»ƒæŸå¤±: {train_loss:.4f}")
        print(f"   éªŒè¯æŸå¤±: {val_loss:.4f}")
        print(f"   MAE: {mae:.4f} (è¶Šå°è¶Šå¥½)")
        print(f"   RMSE: {rmse:.4f}")
        print(f"   ç›¸å…³ç³»æ•°: {correlation:.4f} (è¶Šæ¥è¿‘1è¶Šå¥½)")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if mae < best_mae and not math.isnan(mae):
            best_mae = mae
            best_correlation = correlation
            
            os.makedirs(os.path.dirname(args.save_path), exist_ok=True)
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'mae': mae,
                'correlation': correlation,
                'model_name': args.model
            }, args.save_path)
            print(f"   âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ï¼(MAE: {mae:.4f})")
        
        print()
    
    # è®­ç»ƒå®Œæˆ
    total_time = time.time() - train_start
    print("=" * 60)
    print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
    print("=" * 60)
    print(f"   æ€»è€—æ—¶: {total_time / 60:.1f} åˆ†é’Ÿ")
    print(f"   æœ€ä½³ MAE: {best_mae:.4f}")
    print(f"   æœ€ä½³ç›¸å…³ç³»æ•°: {best_correlation:.4f}")
    print(f"   æ¨¡å‹ä¿å­˜ä½ç½®: {args.save_path}")


if __name__ == "__main__":
    main()
