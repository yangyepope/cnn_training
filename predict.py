"""
é¢„æµ‹è„šæœ¬
========
ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹é¢„æµ‹æ–°å›¾ç‰‡çš„é¢œå€¼åˆ†æ•°

ä½¿ç”¨æ–¹æ³•ï¼š
---------
# é¢„æµ‹å•å¼ å›¾ç‰‡
python predict.py test.jpg

# é¢„æµ‹å¤šå¼ å›¾ç‰‡
python predict.py image1.jpg image2.jpg image3.jpg

# é¢„æµ‹æ•´ä¸ªæ–‡ä»¶å¤¹çš„å›¾ç‰‡
python predict.py --dir /path/to/images

# æŒ‡å®šä½¿ç”¨çš„æ¨¡å‹
python predict.py test.jpg --model_path models/best_model.pth
"""

# ==============================================================================
# å¯¼å…¥å¿…è¦çš„åº“
# ==============================================================================

import os                          # æ“ä½œç³»ç»Ÿæ¥å£
import argparse                    # å‘½ä»¤è¡Œå‚æ•°è§£æ
from pathlib import Path           # è·¯å¾„å¤„ç†

import torch                       # PyTorchæ ¸å¿ƒåº“
from PIL import Image              # å›¾åƒå¤„ç†åº“
from torchvision import transforms # å›¾åƒå˜æ¢

# å¯¼å…¥é…ç½®å’Œæ¨¡å‹
from config import MODEL_SAVE_PATH, IMAGE_SIZE
from model import BeautyModel


# ==============================================================================
# å›¾åƒé¢„å¤„ç†
# ==============================================================================

def get_predict_transform():
    """
    è·å–é¢„æµ‹æ—¶çš„å›¾åƒå˜æ¢
    
    ä¸è®­ç»ƒæ—¶çš„éªŒè¯å˜æ¢ç›¸åŒï¼š
    - ç¼©æ”¾åˆ°æ ‡å‡†å°ºå¯¸
    - è½¬ä¸ºå¼ é‡
    - æ ‡å‡†åŒ–ï¼ˆä½¿ç”¨ImageNetå‡å€¼å’Œæ ‡å‡†å·®ï¼‰
    
    æ³¨æ„ï¼šé¢„æµ‹æ—¶ä¸åšæ•°æ®å¢å¼ºï¼ˆä¸ç¿»è½¬ã€ä¸æ—‹è½¬ã€ä¸è°ƒè‰²ï¼‰
    
    è¿”å›ï¼š
    ------
    transform : torchvision.transforms.Compose
        å˜æ¢æ“ä½œ
    """
    return transforms.Compose([
        # ç¼©æ”¾åˆ° 224x224
        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
        
        # è½¬ä¸ºå¼ é‡
        transforms.ToTensor(),
        
        # æ ‡å‡†åŒ–
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        )
    ])


# ==============================================================================
# åŠ è½½æ¨¡å‹
# ==============================================================================

def load_model(model_path: str, device):
    """
    åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    
    å‚æ•°ï¼š
    ------
    model_path : str
        æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼ˆ.pthæ–‡ä»¶ï¼‰
        
    device : torch.device
        è®¡ç®—è®¾å¤‡ï¼ˆCPUæˆ–GPUï¼‰
    
    è¿”å›ï¼š
    ------
    model : BeautyModel
        åŠ è½½å¥½æƒé‡çš„æ¨¡å‹ï¼Œå·²è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    """
    
    # --------------------------------------------------------------------------
    # åŠ è½½ä¿å­˜çš„æ£€æŸ¥ç‚¹
    # --------------------------------------------------------------------------
    # torch.load ä¼šåŠ è½½æ•´ä¸ªå­—å…¸
    # map_location æŒ‡å®šåŠ è½½åˆ°å“ªä¸ªè®¾å¤‡
    # å¦‚æœæ¨¡å‹æ˜¯åœ¨GPUä¸Šä¿å­˜çš„ï¼Œä½†ç°åœ¨ç”¨CPUï¼Œéœ€è¦ç”¨map_locationè½¬æ¢
    checkpoint = torch.load(model_path, map_location=device)
    
    # è·å–æ¨¡å‹æ¶æ„åç§°ï¼ˆå¦‚æœä¿å­˜æ—¶è®°å½•äº†ï¼‰
    model_name = checkpoint.get('model_name', 'mobilenet')
    
    # --------------------------------------------------------------------------
    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    # --------------------------------------------------------------------------
    # æ³¨æ„ï¼šè¿™é‡Œä¸åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆweights=Noneï¼‰ï¼Œå› ä¸ºæˆ‘ä»¬è¦åŠ è½½è‡ªå·±è®­ç»ƒçš„æƒé‡
    model = BeautyModel(model_name=model_name)
    
    # --------------------------------------------------------------------------
    # åŠ è½½æ¨¡å‹å‚æ•°
    # --------------------------------------------------------------------------
    # model.state_dict() è¿”å›æ¨¡å‹æ‰€æœ‰å‚æ•°çš„å­—å…¸
    # model.load_state_dict() ä»å­—å…¸åŠ è½½å‚æ•°
    model.load_state_dict(checkpoint['model_state_dict'])
    
    # --------------------------------------------------------------------------
    # ç§»åŠ¨åˆ°è®¡ç®—è®¾å¤‡å¹¶è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    # --------------------------------------------------------------------------
    model = model.to(device)
    model.eval()  # è¯„ä¼°æ¨¡å¼ï¼šå…³é—­Dropout
    
    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    print(f"âœ… åŠ è½½æ¨¡å‹æˆåŠŸ: {model_name}")
    print(f"   è®­ç»ƒæ—¶ MAE: {checkpoint.get('mae', 'N/A'):.4f}")
    print(f"   è®­ç»ƒæ—¶ç›¸å…³ç³»æ•°: {checkpoint.get('correlation', 'N/A'):.4f}")
    print(f"   è®­ç»ƒè½®æ•°: {checkpoint.get('epoch', 'N/A')}")
    
    return model


# ==============================================================================
# é¢„æµ‹å•å¼ å›¾ç‰‡
# ==============================================================================

def predict_single_image(model, image_path: str, transform, device):
    """
    é¢„æµ‹å•å¼ å›¾ç‰‡çš„é¢œå€¼åˆ†æ•°
    
    å‚æ•°ï¼š
    ------
    model : BeautyModel
        è®­ç»ƒå¥½çš„æ¨¡å‹
        
    image_path : str
        å›¾ç‰‡æ–‡ä»¶è·¯å¾„
        
    transform : torchvision.transforms.Compose
        å›¾åƒé¢„å¤„ç†å˜æ¢
        
    device : torch.device
        è®¡ç®—è®¾å¤‡
    
    è¿”å›ï¼š
    ------
    result : dict
        é¢„æµ‹ç»“æœå­—å…¸ï¼ŒåŒ…å«ï¼š
        - 'success': æ˜¯å¦æˆåŠŸ
        - 'score': é¢„æµ‹åˆ†æ•°ï¼ˆ1-5åˆ†ï¼‰
        - 'description': åˆ†æ•°çš„æ–‡å­—æè¿°
        - 'error': å¦‚æœå¤±è´¥ï¼ŒåŒ…å«é”™è¯¯ä¿¡æ¯
    """
    
    result = {
        'success': False,
        'score': None,
        'description': None,
        'error': None
    }
    
    try:
        # ----------------------------------------------------------------------
        # è¯»å–å¹¶é¢„å¤„ç†å›¾ç‰‡
        # ----------------------------------------------------------------------
        
        # æ‰“å¼€å›¾ç‰‡å¹¶è½¬ä¸ºRGBæ ¼å¼
        image = Image.open(image_path).convert('RGB')
        
        # åº”ç”¨é¢„å¤„ç†å˜æ¢
        image_tensor = transform(image)
        
        # æ·»åŠ batchç»´åº¦
        # æ¨¡å‹æœŸæœ›è¾“å…¥å½¢çŠ¶æ˜¯ (batch_size, channels, height, width)
        # å•å¼ å›¾ç‰‡éœ€è¦æ·»åŠ ä¸€ä¸ªç»´åº¦ï¼š(3, 224, 224) -> (1, 3, 224, 224)
        image_tensor = image_tensor.unsqueeze(0)
        
        # ç§»åŠ¨åˆ°è®¡ç®—è®¾å¤‡
        image_tensor = image_tensor.to(device)
        
        # ----------------------------------------------------------------------
        # æ¨¡å‹é¢„æµ‹
        # ----------------------------------------------------------------------
        
        # ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ˆåŠ å¿«é€Ÿåº¦ï¼ŒèŠ‚çœå†…å­˜ï¼‰
        with torch.no_grad():
            # å‰å‘ä¼ æ’­
            output = model(image_tensor)
        
        # ----------------------------------------------------------------------
        # å¤„ç†è¾“å‡º
        # ----------------------------------------------------------------------
        
        # output.item() å°†å¼ é‡è½¬ä¸ºPythonæ•°å€¼
        # æ¨¡å‹è¾“å‡ºæ˜¯0-1èŒƒå›´ï¼Œè½¬å›1-5åˆ†
        score = output.item() * 4.0 + 1.0
        
        # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…ï¼ˆç†è®ºä¸ŠSigmoidå·²ç»ä¿è¯0-1ï¼Œä½†ä»¥é˜²ä¸‡ä¸€ï¼‰
        score = max(1.0, min(5.0, score))
        
        result['success'] = True
        result['score'] = score
        result['description'] = get_score_description(score)
        
    except Exception as e:
        result['error'] = str(e)
    
    return result


# ==============================================================================
# åˆ†æ•°æè¿°å‡½æ•°
# ==============================================================================

def get_score_description(score: float) -> str:
    """
    æ ¹æ®åˆ†æ•°è¿”å›æ–‡å­—æè¿°
    
    å‚æ•°ï¼š
    ------
    score : float
        é¢œå€¼åˆ†æ•°ï¼Œ1-5åˆ†
    
    è¿”å›ï¼š
    ------
    description : str
        åˆ†æ•°çš„æ–‡å­—æè¿°
    """
    
    if score >= 4.5:
        return "â­â­â­â­â­ æè‡´ç¾é¢œ"
    elif score >= 4.0:
        return "â­â­â­â­ éå¸¸å¥½çœ‹"
    elif score >= 3.5:
        return "â­â­â­â˜† å¥½çœ‹"
    elif score >= 3.0:
        return "â­â­â­ æ™®é€šåä¸Š"
    elif score >= 2.5:
        return "â­â­â˜† æ™®é€š"
    elif score >= 2.0:
        return "â­â­ æ™®é€šåä¸‹"
    else:
        return "â­ æœ‰æå‡ç©ºé—´"


# ==============================================================================
# ä¸»å‡½æ•°
# ==============================================================================

def main():
    """
    ä¸»å‡½æ•°ï¼šè§£æå‚æ•°å¹¶æ‰§è¡Œé¢„æµ‹
    """
    
    # ==========================================================================
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    # ==========================================================================
    
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨CNNæ¨¡å‹é¢„æµ‹å›¾ç‰‡é¢œå€¼åˆ†æ•°",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    # ä½ç½®å‚æ•°ï¼šå›¾ç‰‡è·¯å¾„ï¼ˆå¯ä»¥å¤šä¸ªï¼‰
    parser.add_argument(
        "images", 
        nargs="*",  # 0ä¸ªæˆ–å¤šä¸ª
        help="è¦é¢„æµ‹çš„å›¾ç‰‡è·¯å¾„"
    )
    
    # å¯é€‰å‚æ•°ï¼šå›¾ç‰‡ç›®å½•
    parser.add_argument(
        "--dir", 
        type=str, 
        default=None,
        help="å›¾ç‰‡ç›®å½•è·¯å¾„ï¼Œé¢„æµ‹ç›®å½•ä¸‹æ‰€æœ‰å›¾ç‰‡"
    )
    
    # å¯é€‰å‚æ•°ï¼šæ¨¡å‹è·¯å¾„
    parser.add_argument(
        "--model_path", 
        type=str, 
        default=MODEL_SAVE_PATH,
        help="æ¨¡å‹æ–‡ä»¶è·¯å¾„"
    )
    
    args = parser.parse_args()
    
    # ==========================================================================
    # æ”¶é›†è¦é¢„æµ‹çš„å›¾ç‰‡
    # ==========================================================================
    
    images = []
    
    # æ·»åŠ å‘½ä»¤è¡ŒæŒ‡å®šçš„å›¾ç‰‡
    if args.images:
        images.extend(args.images)
    
    # æ·»åŠ ç›®å½•ä¸‹çš„å›¾ç‰‡
    if args.dir:
        # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
        supported_ext = {'.jpg', '.jpeg', '.png', '.bmp', '.gif'}
        
        # éå†ç›®å½•
        for f in os.listdir(args.dir):
            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•åï¼ˆè½¬å°å†™åæ¯”è¾ƒï¼‰
            if Path(f).suffix.lower() in supported_ext:
                images.append(os.path.join(args.dir, f))
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡
    if not images:
        print("âŒ è¯·æä¾›è¦é¢„æµ‹çš„å›¾ç‰‡ï¼")
        print()
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python predict.py test.jpg")
        print("  python predict.py image1.jpg image2.jpg")
        print("  python predict.py --dir /path/to/images")
        return
    
    # ==========================================================================
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    # ==========================================================================
    
    if not os.path.exists(args.model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model_path}")
        print()
        print("è¯·å…ˆè¿è¡Œ python train.py è®­ç»ƒæ¨¡å‹")
        return
    
    # ==========================================================================
    # åŠ è½½æ¨¡å‹
    # ==========================================================================
    
    print("=" * 60)
    print("CNN é¢œå€¼é¢„æµ‹")
    print("=" * 60)
    
    # é€‰æ‹©è®¡ç®—è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"\nğŸ“± è®¡ç®—è®¾å¤‡: {device}")
    
    # åŠ è½½æ¨¡å‹
    print(f"\nğŸ“¦ åŠ è½½æ¨¡å‹...")
    model = load_model(args.model_path, device)
    
    # è·å–é¢„å¤„ç†å˜æ¢
    transform = get_predict_transform()
    
    # ==========================================================================
    # é¢„æµ‹å›¾ç‰‡
    # ==========================================================================
    
    print(f"\nğŸš€ å¼€å§‹é¢„æµ‹ {len(images)} å¼ å›¾ç‰‡...\n")
    
    # å­˜å‚¨æ‰€æœ‰åˆ†æ•°ï¼Œç”¨äºæœ€åç»Ÿè®¡
    all_scores = []
    
    # éå†æ¯å¼ å›¾ç‰‡
    for image_path in images:
        # æ‰“å°æ–‡ä»¶å
        filename = Path(image_path).name
        print(f"ğŸ“· {filename}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(image_path):
            print(f"   âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼\n")
            continue
        
        # é¢„æµ‹
        result = predict_single_image(model, image_path, transform, device)
        
        # æ‰“å°ç»“æœ
        if result['success']:
            print(f"   ğŸ¯ é¢œå€¼åˆ†æ•°: {result['score']:.2f} / 5.0")
            print(f"   ğŸ“ {result['description']}")
            all_scores.append(result['score'])
        else:
            print(f"   âŒ é¢„æµ‹å¤±è´¥: {result['error']}")
        
        print()  # ç©ºè¡Œ
    
    # ==========================================================================
    # ç»Ÿè®¡æ±‡æ€»
    # ==========================================================================
    
    if all_scores:
        print("=" * 40)
        print("ğŸ“Š é¢„æµ‹æ±‡æ€»")
        print("=" * 40)
        print(f"   æˆåŠŸé¢„æµ‹: {len(all_scores)} å¼ ")
        print(f"   å¹³å‡åˆ†: {sum(all_scores) / len(all_scores):.2f}")
        print(f"   æœ€é«˜åˆ†: {max(all_scores):.2f}")
        print(f"   æœ€ä½åˆ†: {min(all_scores):.2f}")


# ==============================================================================
# ç¨‹åºå…¥å£
# ==============================================================================

if __name__ == "__main__":
    main()
